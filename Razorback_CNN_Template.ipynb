{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f41d3072",
   "metadata": {},
   "source": [
    "# DASC 41103 â€“ Project 3: CNN Razorback Logo Classifier (Colab Version)\n",
    "\n",
    "This notebook is modeled after the class CNN examples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62fb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 1: Mount Google Drive (Colab)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Drive mounted successfully.\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Google Colab - skipping drive.mount().\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 2: Imports and basic configuration\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "SEED=42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATASET_ROOT = Path(\"/content/drive/MyDrive/DEIN_ORDNER/dataset\")\n",
    "TRAIN_RATIO=0.8\n",
    "BATCH_SIZE=8\n",
    "NUM_EPOCHS=15\n",
    "LEARNING_RATE=1e-3\n",
    "GROUP_NUMBER=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 3: Check folders\n",
    "hogs_dir=DATASET_ROOT/'hogs'\n",
    "no_hogs_dir=DATASET_ROOT/'no_hogs'\n",
    "print(hogs_dir, no_hogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 4: Transforms and dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((500,500)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "base_dataset = datasets.ImageFolder(root=DATASET_ROOT, transform=transform)\n",
    "print(base_dataset.classes, base_dataset.class_to_idx, len(base_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 5: Wrapper dataset\n",
    "class HogLogoDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.ds=ds\n",
    "        m=ds.class_to_idx\n",
    "        self.map={m['hogs']:1, m['no_hogs']:0}\n",
    "    def __len__(self): return len(self.ds)\n",
    "    def __getitem__(self, i):\n",
    "        x,y=self.ds[i]\n",
    "        return x, self.map[y]\n",
    "\n",
    "full_dataset=HogLogoDataset(base_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af2ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 6: Split\n",
    "total=len(full_dataset)\n",
    "train_size=int(TRAIN_RATIO*total)\n",
    "valid_size=total-train_size\n",
    "train_dataset, valid_dataset = random_split(full_dataset,[train_size,valid_size])\n",
    "train_dl=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_dl=DataLoader(valid_dataset,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586fa68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 7: Visualization skipped minimal placeholder\n",
    "print(\"Visualization omitted in this preview notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fce1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 8: Model\n",
    "model=nn.Sequential(\n",
    "    nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64,128,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "    nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(),\n",
    "    nn.Linear(128,64), nn.ReLU(), nn.Dropout(0.5),\n",
    "    nn.Linear(64,2)\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb0f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 9: Loss & optim\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e088ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 10: Train function placeholder\n",
    "def train(model,epochs,train_dl,valid_dl):\n",
    "    print(\"Training loop placeholder (full version too long for preview)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5624a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box 11,12,13,14 omitted for brevity in this downloadable template\n",
    "print(\"Notebook structure complete.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
